{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5 FSOCO Training\n",
    "\n",
    "**Essential steps only:**\n",
    "1. Setup YOLOv5\n",
    "2. Convert FSOCO labels (Supervisely â†’ YOLO)\n",
    "3. Train\n",
    "4. Inference\n",
    "\n",
    "**Run from:** `driverless-ml-dev/perceptions/camera-pipeline/notebooks/`\n",
    "\n",
    "**Activate venv in root/driverless-ml-dev directory, and connect kernel for this notebook to it**\n",
    "open vsc terminal via ctrl+shift+`\n",
    "\n",
    "first time only:\n",
    "```\n",
    "cd ~/driverless-ml-dev\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --name driverless-ml --display-name \"Python (driverless-ml)\" --user\n",
    "```\n",
    "then type `>developer reload` in the search bar at the top\n",
    "\n",
    "to activate venv\n",
    "```\n",
    "cd /root/driverless-ml-dev\n",
    "source venv/bin/activate\n",
    "```\n",
    "then type `>developer reload` in the search bar at the top\n",
    "\n",
    "install libraries with: `pip install pillow tqdm pyyaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ~/driverless-ml-dev\n",
    "# !python -m venv venv\n",
    "# !source venv/bin/activate\n",
    "# !venv/bin/python -m pip install --upgrade pip ipykernel\n",
    "# !venv/bin/python -m ipykernel install --name driverless-ml --display-name \"Python (driverless-ml)\" --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activate venv in root/driverless-ml-dev directory, and connect kernel for this notebook to it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "ROOT = Path.cwd().parent.parent.parent  # driverless-ml-dev/\n",
    "print(ROOT)\n",
    "YOLO_DIR = ROOT / 'yolov5'\n",
    "DATA_DIR = ROOT / 'ml_data'\n",
    "FSOCO_RAW = ROOT / 'ml_data/perceptions/fsoco_raw'  # Download FSOCO here\n",
    "FSOCO_YOLO = ROOT / 'ml_data/perceptions/fsoco_yolo'  # Converted dataset\n",
    "FSOCO_MOD = ROOT / 'ml_data/perceptions/fsoco_mod'  # Working copy for preprocessing\n",
    "\n",
    "print(f\"Root: {ROOT}\")\n",
    "print(f\"YOLOv5: {YOLO_DIR}\")\n",
    "print(f\"Data: {DATA_DIR}\")\n",
    "print(f\"Fsoco_raw: {FSOCO_RAW}\")\n",
    "print(f\"Fsoco_mod: {FSOCO_MOD}\")\n",
    "print(f\"Fsoco_yolo: {FSOCO_YOLO}\")\n",
    "for item in fsoco_mod.iterdir():\n",
    "    print(f\"  - {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone YOLOv5\n",
    "if not YOLO_DIR.exists() and not any(YOLO_DIR.iterdir()):\n",
    "    !cd {ROOT} && git clone https://github.com/ultralytics/yolov5.git\n",
    "    print(\"âœ“ YOLOv5 cloned\")\n",
    "else:\n",
    "    print(\"âœ“ YOLOv5 exists\")\n",
    "\n",
    "# Install requirements\n",
    "%pip install -r {YOLO_DIR}/requirements.txt\n",
    "print(\"âœ“ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download FSOCO Dataset\n",
    "\n",
    "**Manual step required:**\n",
    "1. Visit: https://fsoco.github.io/fsoco-dataset/download\n",
    "2. Download Bounding Boxes dataset (24GB)\n",
    "3. Extract to: `root/ml-data/perceptions/`\n",
    "\n",
    "Expected structure:\n",
    "```\n",
    "root/ml-data/perceptions/\n",
    "â””â”€â”€ fsoco_raw/\n",
    "    â”œâ”€â”€ team1/ann/       # JSON annotations\n",
    "    â”œâ”€â”€ team1/img/       # Images\n",
    "    â””â”€â”€ meta.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def flatten_dataset_structure(dataset_path: str):\n",
    "    \"\"\"\n",
    "    change copies and redoes the downloaded dataset structure from:\n",
    "        dataset/\n",
    "          - meta.json\n",
    "          - team1/ann, team1/img\n",
    "          - team2/ann, team2/img\n",
    "          ...\n",
    "    to:\n",
    "        dataset/\n",
    "          - ann/\n",
    "          - img/\n",
    "          - meta.json\n",
    "    \"\"\"\n",
    "    root = Path(dataset_path)\n",
    "    ann_out = root / \"ann\"\n",
    "    img_out = root / \"img\"\n",
    "\n",
    "    #check output dirs\n",
    "    ann_out.mkdir(exist_ok=True)\n",
    "    img_out.mkdir(exist_ok=True)\n",
    "\n",
    "    for team_dir in root.iterdir():\n",
    "        if team_dir.is_dir() and team_dir.name not in {\"ann\", \"img\"}:\n",
    "            ann_dir = team_dir / \"ann\"\n",
    "            img_dir = team_dir / \"img\"\n",
    "\n",
    "            if ann_dir.exists():\n",
    "                for file in ann_dir.iterdir():\n",
    "                    dest = ann_out / f\"{team_dir.name}_{file.name}\"\n",
    "                    shutil.move(str(file), dest)\n",
    "\n",
    "            # copy img files\n",
    "            if img_dir.exists():\n",
    "                for file in img_dir.iterdir():\n",
    "                    dest = img_out / f\"{team_dir.name}_{file.name}\"\n",
    "                    shutil.move(str(file), dest)\n",
    "\n",
    "            # Clean up empty team dir\n",
    "            shutil.rmtree(team_dir)\n",
    "\n",
    "    print(f\"Flattening complete. Files moved into {ann_out} and {img_out}\")\n",
    "\n",
    "\n",
    "def prepare_working_copy(source_path: Path, dest_path: Path):\n",
    "    \"\"\"Copy the raw dataset into a working directory before mutating it.\"\"\"\n",
    "    if not dest_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"âœ— Working dataset directory not found: {dest_path}\\nCreate this directory before running the preprocessing pipeline.\"\n",
    "        )\n",
    "\n",
    "    if not source_path.exists() or not any(source_path.iterdir()):\n",
    "        raise FileNotFoundError(\n",
    "            f\"âœ— Source dataset not found or empty: {source_path}\\nDownload and extract the FSOCO dataset first.\"\n",
    "        )\n",
    "\n",
    "    print(f\"Preparing working dataset at: {dest_path}\")\n",
    "\n",
    "    # Clear existing contents in the working directory\n",
    "    for item in dest_path.iterdir():\n",
    "        if item.is_dir():\n",
    "            shutil.rmtree(item)\n",
    "        else:\n",
    "            item.unlink()\n",
    "\n",
    "    # Copy fresh contents from the source dataset\n",
    "    for item in source_path.iterdir():\n",
    "        target = dest_path / item.name\n",
    "        if item.is_dir():\n",
    "            shutil.copytree(item, target)\n",
    "        else:\n",
    "            shutil.copy2(item, target)\n",
    "\n",
    "    print(\"âœ“ Working copy created\")\n",
    "\n",
    "\n",
    "raw_exists = FSOCO_RAW.exists()\n",
    "print(any(FSOCO_RAW.iterdir()))\n",
    "print(FSOCO_RAW)\n",
    "raw_has_content = any(FSOCO_RAW.iterdir()) if raw_exists else False\n",
    "print(raw_exists)\n",
    "print(raw_has_content)\n",
    "\n",
    "if raw_exists and raw_has_content:\n",
    "    print(\"âœ“ FSOCO dataset found\")\n",
    "    for item in FSOCO_RAW.iterdir():\n",
    "        print(f\"  - {item.name}\")\n",
    "    print(FSOCO_MOD)\n",
    "    FSOCO_MOD.mkdir(parents=True, exist_ok=True)\n",
    "    prepare_working_copy(FSOCO_RAW, FSOCO_MOD)\n",
    "    flatten_dataset_structure(FSOCO_MOD)\n",
    "# else:\n",
    "#     raise FileNotFoundError(f\"âœ— Download FSOCO dataset to: {FSOCO_RAW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check structure\n",
    "if not FSOCO_MOD.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"âœ— Working dataset directory not found: {FSOCO_MOD}. Run the preparation step and ensure the directory exists.\"\n",
    "    )\n",
    "\n",
    "if not any(FSOCO_MOD.iterdir()):\n",
    "    raise RuntimeError(\n",
    "        f\"âœ— Working dataset directory is empty: {FSOCO_MOD}. Run the preparation step to copy data before proceeding.\"\n",
    "    )\n",
    "\n",
    "working_dataset = FSOCO_MOD\n",
    "print(f\"Inspecting dataset at: {working_dataset}\")\n",
    "\n",
    "bb_path = working_dataset / 'bounding_boxes'\n",
    "if not bb_path.exists():\n",
    "    bb_path = working_dataset / 'ann'\n",
    "\n",
    "print(\"bounding_boxes/ann contents:\")\n",
    "if bb_path.exists():\n",
    "    for item in list(bb_path.iterdir())[:5]:\n",
    "        print(f\"  {item.name}\")\n",
    "else:\n",
    "    print(\"  âœ— No bounding box directory found\")\n",
    "\n",
    "img_path = working_dataset / 'images'\n",
    "if not img_path.exists():\n",
    "    img_path = working_dataset / 'img'\n",
    "\n",
    "print(\"\\nimages/img contents:\")\n",
    "if img_path.exists():\n",
    "    for item in list(img_path.iterdir())[:5]:\n",
    "        print(f\"  {item.name}\")\n",
    "else:\n",
    "    print(\"  âœ— No image directory found\")\n",
    "\n",
    "print(\"\\nmeta.json:\")\n",
    "meta_path = working_dataset / 'meta.json'\n",
    "if meta_path.exists():\n",
    "    import json\n",
    "    meta = json.load(open(meta_path))\n",
    "    print(json.dumps(meta, indent=2)[:500])\n",
    "else:\n",
    "    print(\"  âœ— meta.json not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Images by Aspect Ratio\n",
    "\n",
    "Remove images that don't meet minimum aspect ratio requirements (width/height)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "def filter_images_by_aspect_ratio(fsoco_mod, min_ratio=1.0, max_ratio=3.0):\n",
    "    \"\"\"\n",
    "    Filter out images that don't meet aspect ratio requirements.\n",
    "    \n",
    "    Args:\n",
    "        fsoco_mod: Path to FSOCO dataset\n",
    "        min_ratio: Minimum aspect ratio (width/height)\n",
    "        max_ratio: Maximum aspect ratio (width/height)\n",
    "    \n",
    "    Returns:\n",
    "        List of filtered image paths and count of removed images\n",
    "    \"\"\"\n",
    "    img_dir = fsoco_mod / 'images'\n",
    "    if not img_dir.exists():\n",
    "        img_dir = fsoco_mod / 'img'\n",
    "    ann_dir = fsoco_mod / 'bounding_boxes'\n",
    "    if not ann_dir.exists():\n",
    "        ann_dir = fsoco_mod / 'ann'\n",
    "    \n",
    "    if not img_dir.exists():\n",
    "        print(f\"âœ— Image directory not found: {img_dir}\")\n",
    "        return [], 0\n",
    "    \n",
    "    images = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))\n",
    "    print(f\"Total images found: {len(images)}\")\n",
    "    \n",
    "    filtered_images = []\n",
    "    removed_images = []\n",
    "    kept_dimensions = []\n",
    "    removed_dimensions = []\n",
    "    kept_aspect_ratios = []\n",
    "    removed_aspect_ratios = []\n",
    "    \n",
    "    for img_path in tqdm(images, desc=\"Filtering images by aspect ratio\"):\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            w, h = img.size\n",
    "            aspect_ratio = w / h\n",
    "            \n",
    "            if min_ratio <= aspect_ratio <= max_ratio:\n",
    "                filtered_images.append(img_path)\n",
    "                kept_dimensions.append((w, h))\n",
    "                kept_aspect_ratios.append(aspect_ratio)\n",
    "            else:\n",
    "                # Remove image and corresponding annotation\n",
    "                removed_images.append((img_path, aspect_ratio, w, h))\n",
    "                removed_dimensions.append((w, h))\n",
    "                removed_aspect_ratios.append(aspect_ratio)\n",
    "                \n",
    "                img_path.unlink()  # Delete image\n",
    "                \n",
    "                # Delete corresponding annotation if exists\n",
    "                ann_path = ann_dir / f\"{img_path.name}.json\"\n",
    "                if not ann_path.exists():\n",
    "                    ann_path = ann_dir / f\"{img_path.stem}.json\"\n",
    "                if ann_path.exists():\n",
    "                    ann_path.unlink()\n",
    "                \n",
    "                print(f\"Removed: {img_path.name} (aspect ratio: {aspect_ratio:.2f}, dims: {w}x{h})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FILTERING STATISTICS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š OVERALL SUMMARY:\")\n",
    "    print(f\"  Total images processed:  {len(images)}\")\n",
    "    if images:\n",
    "        print(f\"  âœ“ Images kept:           {len(filtered_images)} ({100*len(filtered_images)/len(images):.1f}%)\")\n",
    "        print(f\"  âœ— Images filtered out:   {len(removed_images)} ({100*len(removed_images)/len(images):.1f}%)\")\n",
    "    else:\n",
    "        print(\"  âœ“ Images kept:           0\")\n",
    "        print(\"  âœ— Images filtered out:   0\")\n",
    "    print(f\"  Aspect ratio range:      {min_ratio} - {max_ratio}\")\n",
    "    \n",
    "    if kept_aspect_ratios:\n",
    "        print(f\"\\nðŸ“ KEPT IMAGES - ASPECT RATIO STATS:\")\n",
    "        print(f\"  Min aspect ratio:  {min(kept_aspect_ratios):.2f}\")\n",
    "        print(f\"  Max aspect ratio:  {max(kept_aspect_ratios):.2f}\")\n",
    "        print(f\"  Avg aspect ratio:  {sum(kept_aspect_ratios)/len(kept_aspect_ratios):.2f}\")\n",
    "    \n",
    "    if kept_dimensions:\n",
    "        print(f\"\\nðŸ“ KEPT IMAGES - DIMENSION STATS:\")\n",
    "        dim_counter = Counter(kept_dimensions)\n",
    "        top_dims = dim_counter.most_common(10)\n",
    "        print(f\"  Unique dimensions: {len(dim_counter)}\")\n",
    "        print(f\"  Top 10 dimensions:\")\n",
    "        for (w, h), count in top_dims:\n",
    "            ratio = w/h\n",
    "            print(f\"    {w}x{h} (ratio {ratio:.2f}): {count} images\")\n",
    "    \n",
    "    if removed_aspect_ratios:\n",
    "        print(f\"\\nðŸš« REMOVED IMAGES - ASPECT RATIO STATS:\")\n",
    "        print(f\"  Min aspect ratio:  {min(removed_aspect_ratios):.2f}\")\n",
    "        print(f\"  Max aspect ratio:  {max(removed_aspect_ratios):.2f}\")\n",
    "        print(f\"  Avg aspect ratio:  {sum(removed_aspect_ratios)/len(removed_aspect_ratios):.2f}\")\n",
    "    \n",
    "    if removed_dimensions:\n",
    "        print(f\"\\nðŸš« REMOVED IMAGES - DIMENSION STATS:\")\n",
    "        dim_counter = Counter(removed_dimensions)\n",
    "        print(f\"  Unique dimensions: {len(dim_counter)}\")\n",
    "        print(f\"  All removed dimensions:\")\n",
    "        for (w, h), count in sorted(dim_counter.items(), key=lambda x: x[1], reverse=True):\n",
    "            ratio = w/h\n",
    "            print(f\"    {w}x{h} (ratio {ratio:.2f}): {count} images\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "    \n",
    "    return filtered_images, len(removed_images)\n",
    "\n",
    "# Run filtering\n",
    "MIN_ASPECT_RATIO = 1.0  # Minimum width/height ratio\n",
    "MAX_ASPECT_RATIO = 3.5  # Maximum width/height ratio\n",
    "\n",
    "if not FSOCO_MOD.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"âœ— Working dataset directory not found: {FSOCO_MOD}. Create it and rerun the preparation step before filtering.\"\n",
    "    )\n",
    "\n",
    "if not any(FSOCO_MOD.iterdir()):\n",
    "    raise RuntimeError(\n",
    "        f\"âœ— Working dataset directory is empty: {FSOCO_MOD}. Run the preparation step to copy data before filtering.\"\n",
    "    )\n",
    "\n",
    "print(f\"Using working dataset: {FSOCO_MOD}\")\n",
    "filtered_imgs, removed = filter_images_by_aspect_ratio(\n",
    "    FSOCO_MOD,\n",
    "    min_ratio=MIN_ASPECT_RATIO,\n",
    "    max_ratio=MAX_ASPECT_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert Labels: Supervisely â†’ YOLO\n",
    "\n",
    "YOLO format: `<class_id> <x_center> <y_center> <width> <height>` (all normalized 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Add code for conversion\n",
    "\n",
    "def convert_supervisely_to_yolo(fsoco_raw, fsoco_yolo, split=(0.8, 0.1, 0.1)):\n",
    "    \"\"\"Convert FSOCO Supervisely format to YOLO format.\"\"\"\n",
    "    \n",
    "    # Create directories\n",
    "    for s in ['train', 'val', 'test']:\n",
    "        (fsoco_yolo / 'images' / s).mkdir(parents=True, exist_ok=True)\n",
    "        (fsoco_yolo / 'labels' / s).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load class names from meta.json (only rectangle classes for bounding boxes)\n",
    "    meta = json.load(open(fsoco_raw / 'meta.json'))\n",
    "    classes = [c['title'] for c in meta['classes'] if c['shape'] == 'rectangle']\n",
    "    class_map = {name: i for i, name in enumerate(classes)}\n",
    "    print(f\"Classes (bounding boxes only): {classes}\\n\")\n",
    "    \n",
    "    # Get all annotation files\n",
    "    ann_dir = fsoco_raw / 'bounding_boxes'\n",
    "    img_dir = fsoco_raw / 'images'\n",
    "    \n",
    "    ann_files = list(ann_dir.glob('*.json'))\n",
    "    print(f\"Total annotations: {len(ann_files)}\")\n",
    "    \n",
    "    # Split dataset\n",
    "    random.shuffle(ann_files)\n",
    "    n1 = int(len(ann_files) * split[0])\n",
    "    n2 = int(len(ann_files) * (split[0] + split[1]))\n",
    "    splits = {\n",
    "        'train': ann_files[:n1],\n",
    "        'val': ann_files[n1:n2],\n",
    "        'test': ann_files[n2:]\n",
    "    }\n",
    "    \n",
    "    # Convert each split\n",
    "    for split_name, anns in splits.items():\n",
    "        print(f\"\\nConverting {split_name}: {len(anns)} images\")\n",
    "        \n",
    "        for ann_path in tqdm(anns):\n",
    "            # Find corresponding image (handle both .jpg and .png)\n",
    "            img_name = ann_path.stem  # e.g., \"amz_00588.jpg\" from \"amz_00588.jpg.json\"\n",
    "            img_path = img_dir / img_name\n",
    "            \n",
    "            if not img_path.exists():\n",
    "                # Try alternate extension\n",
    "                alt_name = img_name.replace('.jpg', '.png') if '.jpg' in img_name else img_name.replace('.png', '.jpg')\n",
    "                img_path = img_dir / alt_name\n",
    "                if not img_path.exists():\n",
    "                    continue\n",
    "            \n",
    "            # Read image dimensions\n",
    "            img = Image.open(img_path)\n",
    "            w, h = img.size\n",
    "            \n",
    "            # Read annotations\n",
    "            ann = json.load(open(ann_path))\n",
    "            \n",
    "            # Convert to YOLO format\n",
    "            yolo_labels = []\n",
    "            for obj in ann.get('objects', []):\n",
    "                cls = obj['classTitle']\n",
    "                if cls not in class_map or obj['geometryType'] != 'rectangle':\n",
    "                    continue\n",
    "                \n",
    "                points = obj['points']['exterior']\n",
    "                x1, y1 = points[0]\n",
    "                x2, y2 = points[1]\n",
    "                \n",
    "                # Convert to YOLO format (center_x, center_y, width, height) normalized\n",
    "                x_center = ((x1 + x2) / 2) / w\n",
    "                y_center = ((y1 + y2) / 2) / h\n",
    "                width = abs(x2 - x1) / w\n",
    "                height = abs(y2 - y1) / h\n",
    "                \n",
    "                # Clamp to [0, 1]\n",
    "                x_center = max(0, min(1, x_center))\n",
    "                y_center = max(0, min(1, y_center))\n",
    "                width = max(0, min(1, width))\n",
    "                height = max(0, min(1, height))\n",
    "                \n",
    "                yolo_labels.append(f\"{class_map[cls]} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "            \n",
    "            # Save image and label\n",
    "            if yolo_labels:  # Only save if there are labels\n",
    "                shutil.copy(img_path, fsoco_yolo / 'images' / split_name / img_path.name)\n",
    "                with open(fsoco_yolo / 'labels' / split_name / f\"{img_path.stem}.txt\", 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_labels))\n",
    "    \n",
    "    print(\"\\nâœ“ Conversion complete\")\n",
    "    print(f\"\\nDataset splits:\")\n",
    "    for split_name in ['train', 'val', 'test']:\n",
    "        n_imgs = len(list((fsoco_yolo / 'images' / split_name).glob('*.[jp][pn]g')))\n",
    "        print(f\"  {split_name}: {n_imgs} images\")\n",
    "    \n",
    "    return classes\n",
    "\n",
    "# Run conversion\n",
    "if FSOCO_MOD.exists() and any(FSOCO_MOD.iterdir()):\n",
    "    classes = convert_supervisely_to_yolo(FSOCO_MOD, FSOCO_YOLO)\n",
    "else:\n",
    "    print(\"Download dataset first!\")\n",
    "    classes = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Dataset Config (YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "if classes:\n",
    "    config = {\n",
    "        'path': str(FSOCO_YOLO.absolute()),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'test': 'images/test',\n",
    "        'nc': len(classes),\n",
    "        'names': classes\n",
    "    }\n",
    "    \n",
    "    config_path = FSOCO_YOLO / 'fsoco.yaml'\n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "    \n",
    "    print(\"âœ“ Config saved:\", config_path)\n",
    "    print(yaml.dump(config, default_flow_style=False))\n",
    "else:\n",
    "    print(\"Convert dataset first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "\n",
    "import torch\n",
    "MODEL = 'yolov5n'  # Options: yolov5n, yolov5s, yolov5m, yolov5l, yolov5x\n",
    "EPOCHS = 10\n",
    "BATCH = 2\n",
    "IMG_SIZE = 640\n",
    "DEVICE = \"0\" if torch.cuda.is_available() else \"cpu\"\n",
    "rect = True \n",
    "print(f\"Model: {MODEL}, Epochs: {EPOCHS}, Batch: {BATCH}, Image size: {IMG_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "%cd $YOLO_DIR\n",
    "!python train.py \\\n",
    "    --img {IMG_SIZE} \\\n",
    "    --batch {BATCH} \\\n",
    "    --epochs {EPOCHS} \\\n",
    "    --data {config_path} \\\n",
    "    --weights {MODEL}.pt \\\n",
    "    --name fsoco_{MODEL} \\\n",
    "    --rect {rect} \\\n",
    "    --cache \\\n",
    "    --device {DEVICE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage\n",
    "\n",
    "# Find latest run\n",
    "runs = sorted((YOLO_DIR / 'runs' / 'train').glob('fsoco_*'), key=lambda x: x.stat().st_mtime)\n",
    "if runs:\n",
    "    latest = runs[-1]\n",
    "    print(f\"Training run: {latest.name}\\n\")\n",
    "    \n",
    "    # Show results\n",
    "    results_img = latest / 'results.png'\n",
    "    if results_img.exists():\n",
    "        display(IPImage(filename=str(results_img)))\n",
    "    \n",
    "    print(f\"\\nWeights: {latest / 'weights' / 'best.pt'}\")\n",
    "else:\n",
    "    print(\"No training runs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trained weights\n",
    "if runs:\n",
    "    weights = runs[-1] / 'weights' / 'best.pt'\n",
    "    test_imgs = FSOCO_YOLO / 'images' / 'test'\n",
    "    \n",
    "    if weights.exists() and test_imgs.exists():\n",
    "        print(\"Running inference...\\n\")\n",
    "        \n",
    "        !python {YOLO_DIR}/detect.py \\\n",
    "            --weights {weights} \\\n",
    "            --source {test_imgs} \\\n",
    "            --img {IMG_SIZE} \\\n",
    "            --conf 0.25 \\\n",
    "            --name fsoco_inference \\\n",
    "            --max-det 100\n",
    "        \n",
    "        # Show results\n",
    "        detect_runs = sorted((YOLO_DIR / 'runs' / 'detect').glob('fsoco_inference*'), \n",
    "                           key=lambda x: x.stat().st_mtime)\n",
    "        if detect_runs:\n",
    "            print(f\"\\nResults saved to: {detect_runs[-1]}\")\n",
    "            \n",
    "            # Display first result\n",
    "            results = list(detect_runs[-1].glob('*.jpg'))[:1]\n",
    "            for r in results:\n",
    "                display(IPImage(filename=str(r), width=800))\n",
    "    else:\n",
    "        print(\"Missing weights or test images\")\n",
    "else:\n",
    "    print(\"Train model first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "**Your model is trained and ready to use.**\n",
    "\n",
    "**Quick commands:**\n",
    "```bash\n",
    "# Inference on images\n",
    "python yolov5/detect.py --weights runs/train/fsoco_yolov5s/weights/best.pt --source /path/to/images\n",
    "\n",
    "# Inference on video\n",
    "python yolov5/detect.py --weights runs/train/fsoco_yolov5s/weights/best.pt --source video.mp4\n",
    "\n",
    "# Inference on webcam\n",
    "python yolov5/detect.py --weights runs/train/fsoco_yolov5s/weights/best.pt --source 0\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
